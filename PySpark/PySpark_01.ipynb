{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbXGDPb3jhKkj/JtOTvQtn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrielfernandorey/EDVAI/blob/main/PySpark/PySpark_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PySpark"
      ],
      "metadata": {
        "id": "oEi-fQEruZwC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instalación y carga de Pyspark"
      ],
      "metadata": {
        "id": "RAb-HoncufBG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLHCz25guPhi",
        "outputId": "cdae592b-43c9-4091-f34b-23d0a7acced2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.9/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317145 sha256=431c8e84b174529f4deca834bee4bb25a504c3b7490b5408df575fc89d4f95ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/34/a4/159aa12d0a510d5ff7c8f0220abbea42e5d81ecf588c4fd884\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "OxYbGIUDujGu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName('test_pyspark').getOrCreate()"
      ],
      "metadata": {
        "id": "bPXjeEj7usAm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Librerías necesarias"
      ],
      "metadata": {
        "id": "sZp8-N6eu9pI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StringType, BooleanType, FloatType, IntegerType, DoubleType, DateType\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.functions import sum, col, desc, asc, count, countDistinct, round, max, min, avg\n",
        "from pyspark.sql.functions import to_timestamp,date_format\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "from pyspark.ml import Transformer\n",
        "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, HasInputCols, HasOutputCols, Param, Params, TypeConverters\n",
        "from pyspark import keyword_only\n",
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "from pyspark.ml import Model\n",
        "from pyspark.ml import Estimator\n",
        "\n",
        "from datetime import datetime\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "M1YNnp6Cu5Rk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importamos datos"
      ],
      "metadata": {
        "id": "Pw2j9WwvvuiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://data-engineer-edvai.s3.amazonaws.com/yellow_tripdata_2021-01.csv"
      ],
      "metadata": {
        "id": "gLOW3Dncro0h",
        "outputId": "7e4a6e60-7a40-4aa0-ddd8-dc191e37e3e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-14 21:31:57--  https://data-engineer-edvai.s3.amazonaws.com/yellow_tripdata_2021-01.csv\n",
            "Resolving data-engineer-edvai.s3.amazonaws.com (data-engineer-edvai.s3.amazonaws.com)... 52.217.18.84, 54.231.229.137, 52.216.136.3, ...\n",
            "Connecting to data-engineer-edvai.s3.amazonaws.com (data-engineer-edvai.s3.amazonaws.com)|52.217.18.84|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 125981363 (120M) [text/csv]\n",
            "Saving to: ‘yellow_tripdata_2021-01.csv’\n",
            "\n",
            "yellow_tripdata_202 100%[===================>] 120.14M  65.5MB/s    in 1.8s    \n",
            "\n",
            "2023-04-14 21:31:59 (65.5 MB/s) - ‘yellow_tripdata_2021-01.csv’ saved [125981363/125981363]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.option(\"header\",\"true\").csv(\"*.csv\")"
      ],
      "metadata": {
        "id": "ot4Z25IXvpVi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "id": "Phpx_gWjy0HN",
        "outputId": "1f12c03e-fba0-4f77-faca-225ee1489ae4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- VendorID: string (nullable = true)\n",
            " |-- tpep_pickup_datetime: string (nullable = true)\n",
            " |-- tpep_dropoff_datetime: string (nullable = true)\n",
            " |-- passenger_count: string (nullable = true)\n",
            " |-- trip_distance: string (nullable = true)\n",
            " |-- RatecodeID: string (nullable = true)\n",
            " |-- store_and_fwd_flag: string (nullable = true)\n",
            " |-- PULocationID: string (nullable = true)\n",
            " |-- DOLocationID: string (nullable = true)\n",
            " |-- payment_type: string (nullable = true)\n",
            " |-- fare_amount: string (nullable = true)\n",
            " |-- extra: string (nullable = true)\n",
            " |-- mta_tax: string (nullable = true)\n",
            " |-- tip_amount: string (nullable = true)\n",
            " |-- tolls_amount: string (nullable = true)\n",
            " |-- improvement_surcharge: string (nullable = true)\n",
            " |-- total_amount: string (nullable = true)\n",
            " |-- congestion_surcharge: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFktEdm-wTYt",
        "outputId": "a4601f8b-4718-4c16-f269-ec9e610cc5ae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
            "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
            "|       1| 2021-01-01 00:30:10|  2021-01-01 00:36:12|              1|         2.10|         1|                 N|         142|          43|           2|          8|    3|    0.5|         0|           0|                  0.3|        11.8|                 2.5|\n",
            "|       1| 2021-01-01 00:51:20|  2021-01-01 00:52:19|              1|          .20|         1|                 N|         238|         151|           2|          3|  0.5|    0.5|         0|           0|                  0.3|         4.3|                   0|\n",
            "|       1| 2021-01-01 00:43:30|  2021-01-01 01:11:06|              1|        14.70|         1|                 N|         132|         165|           1|         42|  0.5|    0.5|      8.65|           0|                  0.3|       51.95|                   0|\n",
            "|       1| 2021-01-01 00:15:48|  2021-01-01 00:31:01|              0|        10.60|         1|                 N|         138|         132|           1|         29|  0.5|    0.5|      6.05|           0|                  0.3|       36.35|                   0|\n",
            "|       2| 2021-01-01 00:31:49|  2021-01-01 00:48:21|              1|         4.94|         1|                 N|          68|          33|           1|       16.5|  0.5|    0.5|      4.06|           0|                  0.3|       24.36|                 2.5|\n",
            "|       1| 2021-01-01 00:16:29|  2021-01-01 00:24:30|              1|         1.60|         1|                 N|         224|          68|           1|          8|    3|    0.5|      2.35|           0|                  0.3|       14.15|                 2.5|\n",
            "|       1| 2021-01-01 00:00:28|  2021-01-01 00:17:28|              1|         4.10|         1|                 N|          95|         157|           2|         16|  0.5|    0.5|         0|           0|                  0.3|        17.3|                   0|\n",
            "|       1| 2021-01-01 00:12:29|  2021-01-01 00:30:34|              1|         5.70|         1|                 N|          90|          40|           2|         18|    3|    0.5|         0|           0|                  0.3|        21.8|                 2.5|\n",
            "|       1| 2021-01-01 00:39:16|  2021-01-01 01:00:13|              1|         9.10|         1|                 N|          97|         129|           4|       27.5|  0.5|    0.5|         0|           0|                  0.3|        28.8|                   0|\n",
            "|       1| 2021-01-01 00:26:12|  2021-01-01 00:39:46|              2|         2.70|         1|                 N|         263|         142|           1|         12|    3|    0.5|      3.15|           0|                  0.3|       18.95|                 2.5|\n",
            "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insertar en la tabla payments (VendorID, tpep_pickup_datetetime, payment_type, total_amount) Solamente los pagos con tarjeta de crédito"
      ],
      "metadata": {
        "id": "9ZK8KNh3w9j8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos vista\n",
        "df.createOrReplaceTempView(\"yellow_tripdata\")"
      ],
      "metadata": {
        "id": "zRX6N9lKxIUB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_5 = spark.sql(\"select VendorId, cast(tpep_pickup_datetime as date), cast(payment_type as int), total_amount from yellow_tripdata where payment_type = 1\")"
      ],
      "metadata": {
        "id": "TTnw0XzyxhfJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_5.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Op8PLPkDE1dY",
        "outputId": "ef5e465d-98d0-476c-f73e-d68adb6563dd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+------------+------------+\n",
            "|VendorId|tpep_pickup_datetime|payment_type|total_amount|\n",
            "+--------+--------------------+------------+------------+\n",
            "|       1|          2021-01-01|           1|       51.95|\n",
            "|       1|          2021-01-01|           1|       36.35|\n",
            "|       2|          2021-01-01|           1|       24.36|\n",
            "|       1|          2021-01-01|           1|       14.15|\n",
            "|       1|          2021-01-01|           1|       18.95|\n",
            "|       2|          2021-01-01|           1|        24.3|\n",
            "|       2|          2021-01-01|           1|       10.79|\n",
            "|       2|          2021-01-01|           1|       14.16|\n",
            "|       2|          2021-01-01|           1|        10.3|\n",
            "|       2|          2021-01-01|           1|       12.09|\n",
            "+--------+--------------------+------------+------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insertar en la tabla passengers (tpep_pickup_datetetime, passenger_count, total_amount) los registros cuya cantidad de pasajeros sea mayor a 2 y el total del viaje cueste más de 8 dólares."
      ],
      "metadata": {
        "id": "4cX43Y-oLz6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_6 = spark.sql(\"select cast(tpep_pickup_datetime as date) as tpep_pickup_date , passenger_count, total_amount from yellow_tripdata where passenger_count >2 and total_amount > 8\")"
      ],
      "metadata": {
        "id": "sdAS6fjGL2v7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_6.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mWImGDQN9QY",
        "outputId": "3d64ef16-9e53-49b2-adac-5bc0d4a2ea64"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+---------------+------------+\n",
            "|tpep_pickup_date|passenger_count|total_amount|\n",
            "+----------------+---------------+------------+\n",
            "|      2021-01-01|              3|        24.3|\n",
            "|      2021-01-01|              5|       14.16|\n",
            "|      2021-01-01|              3|         9.3|\n",
            "|      2021-01-01|              4|        18.3|\n",
            "|      2021-01-01|              4|        13.3|\n",
            "|      2021-01-01|              3|        40.3|\n",
            "|      2021-01-01|              5|        14.8|\n",
            "|      2021-01-01|              3|       18.59|\n",
            "|      2021-01-01|              3|       13.56|\n",
            "|      2021-01-01|              3|        9.96|\n",
            "+----------------+---------------+------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los valores son aproximados pero no exactos al resultado real"
      ],
      "metadata": {
        "id": "o0WOXzy1W8gQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insertar en la tabla tolls (tpep_pickup_datetetime, passenger_count, tolls_amount, total_amount) los registros que tengan pago de peajes mayores a 0.1 y cantidad de pasajeros mayores a 1."
      ],
      "metadata": {
        "id": "xvZ8GhcvXHMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_7 = spark.sql(\"select cast(tpep_pickup_datetime as date) as tpep_pickup_date, passenger_count, tolls_amount, total_amount from yellow_tripdata where tolls_amount > 0.1 and passenger_count > 1 \")"
      ],
      "metadata": {
        "id": "0O-lD4tzOAE-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_7.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4TPNeSlX06b",
        "outputId": "ae25574b-a33d-49aa-e698-3f8869375e98"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+---------------+------------+------------+\n",
            "|tpep_pickup_date|passenger_count|tolls_amount|total_amount|\n",
            "+----------------+---------------+------------+------------+\n",
            "|      2021-01-01|              2|        6.12|       33.92|\n",
            "|      2021-01-01|              2|        6.12|       59.42|\n",
            "|      2021-01-01|              2|        6.12|       35.92|\n",
            "|      2021-01-01|              6|        6.12|        40.1|\n",
            "|      2021-01-01|              3|        6.12|          54|\n",
            "|      2021-01-01|              2|         2.8|        34.1|\n",
            "|      2021-01-01|              4|        6.12|       61.42|\n",
            "|      2021-01-01|              4|        6.12|       51.42|\n",
            "|      2021-01-01|              2|       11.75|       12.05|\n",
            "|      2021-01-01|              6|        6.12|       71.42|\n",
            "+----------------+---------------+------------+------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insertar en la tabla congestion (tpep_pickup_datetetime, passenger_count, congestion_surcharge, total_amount) los registros que hayan tenido congestión en los viajes en la fecha 2021-01-18"
      ],
      "metadata": {
        "id": "MJaf7Da_YW1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_8 = spark.sql(\"select cast(tpep_pickup_datetime as date) as tpep_pickup_date, passenger_count, congestion_surchage, total_amount from yellow_tripdata where cast(tpep_pickup_datetime as date) as tpep_pickup_date = '2021-01-18' \")"
      ],
      "metadata": {
        "id": "GDswU_JYX3WS",
        "outputId": "214ff462-89e2-49d3-811b-d52e4e9b97c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParseException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParseException\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-24ba8a99ce26>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"select cast(tpep_pickup_datetime as date) as tpep_pickup_date, passenger_count, congestion_surchage, total_amount from yellow_tripdata where cast(tpep_pickup_datetime as date) as tpep_pickup_date = '2021-01-18' \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m             \u001b[0mlitArgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_to_java_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1440\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitArgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1441\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mParseException\u001b[0m: \n[PARSE_SYNTAX_ERROR] Syntax error at or near 'as'.(line 1, pos 176)\n\n== SQL ==\nselect cast(tpep_pickup_datetime as date) as tpep_pickup_date, passenger_count, congestion_surchage, total_amount from yellow_tripdata where cast(tpep_pickup_datetime as date) as tpep_pickup_date = '2021-01-18' \n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------^^^\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_8.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YwXc86sY90o",
        "outputId": "9225eb08-1462-4465-85cb-daafbb62c527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------------+\n",
            "|trip_distance|tpep_pickup_date|\n",
            "+-------------+----------------+\n",
            "|          2.7|      2021-01-01|\n",
            "|         6.11|      2021-01-01|\n",
            "|         1.21|      2021-01-01|\n",
            "|          1.7|      2021-01-01|\n",
            "|         1.16|      2021-01-01|\n",
            "|         3.15|      2021-01-01|\n",
            "|         0.64|      2021-01-01|\n",
            "|        10.74|      2021-01-01|\n",
            "|         2.01|      2021-01-01|\n",
            "|         3.45|      2021-01-01|\n",
            "|         2.85|      2021-01-01|\n",
            "|         1.68|      2021-01-01|\n",
            "|         0.77|      2021-01-01|\n",
            "|         0.52|      2021-01-01|\n",
            "|          0.4|      2021-01-01|\n",
            "|         1.05|      2021-01-01|\n",
            "|         5.85|      2021-01-01|\n",
            "|          3.7|      2021-01-01|\n",
            "|        16.54|      2021-01-01|\n",
            "|          4.0|      2021-01-01|\n",
            "+-------------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}